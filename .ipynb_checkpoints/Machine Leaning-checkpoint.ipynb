{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"t.csv\") #random songs of 1990-2010. length is 7683. 100 of them are of the billboard top100.\n",
    "df = df[(df[\"year\"] >= 1990) & (df[\"year\"] <= 2010)] #1990-2010\n",
    "df_top=pd.read_csv(\"audio_features.csv\") #billboard top100 songs audio_features\n",
    "\n",
    "#drop the unnecessary column\n",
    "df=df.drop(\"Unnamed: 0\", axis=1)\n",
    "df_top=df_top.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2013\n",
       "1       2013\n",
       "2       2013\n",
       "3       2013\n",
       "4       2013\n",
       "        ... \n",
       "5653    1959\n",
       "5654    1959\n",
       "5655    1959\n",
       "5656    1959\n",
       "5657    1959\n",
       "Name: year, Length: 5658, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9290, 24)\n",
      "0    7583\n",
      "1    1707\n",
      "Name: bbd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.bbd.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df includes the 9290 songs from 1990-2010. 1707 songs of them are on the billboard top100. I categorized by the column \"bbd\" which is if 1, it's top100, if 0, it's not top100.<br>\n",
    "\"t.csv\" includes the information above. The process of generating \"t.csv\" is in the file \"learning data set.ipynb\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "1. Before deviding the dataset, I need to clean the data and check if there are some null data or broken data.\n",
    "2. Devide the data into training and test data set.\n",
    "3. use some machine learning to predict weather the songs are in top100 or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df has 7683 songs data, and 100 of them are in the billboard top 100.(represent it as \"bbd\" = 0 or 1.) What I am going to do is to apply some machine learning methods to predict if the song is on top100 or not(\"bbd == 0 or 1\") and try to see which one works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_name</th>\n",
       "      <th>sp_artist</th>\n",
       "      <th>sp_url</th>\n",
       "      <th>year</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_href</th>\n",
       "      <th>type</th>\n",
       "      <th>uri</th>\n",
       "      <th>valence</th>\n",
       "      <th>bbd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Shake 'Em On Down</td>\n",
       "      <td>North Mississippi Allstars</td>\n",
       "      <td>https://open.spotify.com/track/0c89AX1OJlQM22d...</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0c89...</td>\n",
       "      <td>0.676</td>\n",
       "      <td>248960</td>\n",
       "      <td>0.869</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.771</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>123.586</td>\n",
       "      <td>4</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/0c89AX1OJlQM...</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:0c89AX1OJlQM22def9hr0n</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Hontelot pojat</td>\n",
       "      <td>Zen Cafe</td>\n",
       "      <td>https://open.spotify.com/track/6KueNqgmnkZyu1D...</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6Kue...</td>\n",
       "      <td>0.658</td>\n",
       "      <td>255427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>89.012</td>\n",
       "      <td>4</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6KueNqgmnkZy...</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:6KueNqgmnkZyu1DaeNxQgL</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Affiliated With the Suffering</td>\n",
       "      <td>Blood Red Throne</td>\n",
       "      <td>https://open.spotify.com/track/7Dt9OJhzn7gQ8ur...</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/7Dt9...</td>\n",
       "      <td>0.395</td>\n",
       "      <td>246867</td>\n",
       "      <td>0.981</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.696</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>199.051</td>\n",
       "      <td>4</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/7Dt9OJhzn7gQ...</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:7Dt9OJhzn7gQ8urVeW59t5</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Estoy Aquí</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>https://open.spotify.com/track/4M1lEbqPzlEw1JY...</td>\n",
       "      <td>1995</td>\n",
       "      <td>66</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4M1l...</td>\n",
       "      <td>0.732</td>\n",
       "      <td>232467</td>\n",
       "      <td>0.814</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>116.973</td>\n",
       "      <td>4</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/4M1lEbqPzlEw...</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:4M1lEbqPzlEw1JYWB6aE7K</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Tune Up - Take 5</td>\n",
       "      <td>Wes Montgomery</td>\n",
       "      <td>https://open.spotify.com/track/5ta4df06VXtrLMW...</td>\n",
       "      <td>1991</td>\n",
       "      <td>9</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/5ta4...</td>\n",
       "      <td>0.589</td>\n",
       "      <td>190893</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.285</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>135.017</td>\n",
       "      <td>4</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5ta4df06VXtr...</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>spotify:track:5ta4df06VXtrLMW9avtjV6</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sp_name                   sp_artist  \\\n",
       "0              Shake 'Em On Down  North Mississippi Allstars   \n",
       "1                 Hontelot pojat                    Zen Cafe   \n",
       "2  Affiliated With the Suffering            Blood Red Throne   \n",
       "3                     Estoy Aquí                     Shakira   \n",
       "4               Tune Up - Take 5              Wes Montgomery   \n",
       "\n",
       "                                              sp_url  year  popularity  \\\n",
       "0  https://open.spotify.com/track/0c89AX1OJlQM22d...  2000          32   \n",
       "1  https://open.spotify.com/track/6KueNqgmnkZyu1D...  2005           9   \n",
       "2  https://open.spotify.com/track/7Dt9OJhzn7gQ8ur...  2003           8   \n",
       "3  https://open.spotify.com/track/4M1lEbqPzlEw1JY...  1995          66   \n",
       "4  https://open.spotify.com/track/5ta4df06VXtrLMW...  1991           9   \n",
       "\n",
       "   acousticness                                       analysis_url  \\\n",
       "0      0.011200  https://api.spotify.com/v1/audio-analysis/0c89...   \n",
       "1      0.067700  https://api.spotify.com/v1/audio-analysis/6Kue...   \n",
       "2      0.000004  https://api.spotify.com/v1/audio-analysis/7Dt9...   \n",
       "3      0.030700  https://api.spotify.com/v1/audio-analysis/4M1l...   \n",
       "4      0.962000  https://api.spotify.com/v1/audio-analysis/5ta4...   \n",
       "\n",
       "   danceability  duration_ms  energy  ... loudness  mode  speechiness  \\\n",
       "0         0.676       248960   0.869  ...   -7.771     1       0.0864   \n",
       "1         0.658       255427   0.573  ...   -6.396     0       0.0289   \n",
       "2         0.395       246867   0.981  ...   -4.696     1       0.2310   \n",
       "3         0.732       232467   0.814  ...   -7.716     1       0.0402   \n",
       "4         0.589       190893   0.143  ...  -23.285     1       0.0311   \n",
       "\n",
       "     tempo  time_signature                                         track_href  \\\n",
       "0  123.586               4  https://api.spotify.com/v1/tracks/0c89AX1OJlQM...   \n",
       "1   89.012               4  https://api.spotify.com/v1/tracks/6KueNqgmnkZy...   \n",
       "2  199.051               4  https://api.spotify.com/v1/tracks/7Dt9OJhzn7gQ...   \n",
       "3  116.973               4  https://api.spotify.com/v1/tracks/4M1lEbqPzlEw...   \n",
       "4  135.017               4  https://api.spotify.com/v1/tracks/5ta4df06VXtr...   \n",
       "\n",
       "             type                                   uri  valence bbd  \n",
       "0  audio_features  spotify:track:0c89AX1OJlQM22def9hr0n    0.698   0  \n",
       "1  audio_features  spotify:track:6KueNqgmnkZyu1DaeNxQgL    0.698   0  \n",
       "2  audio_features  spotify:track:7Dt9OJhzn7gQ8urVeW59t5    0.188   0  \n",
       "3  audio_features  spotify:track:4M1lEbqPzlEw1JYWB6aE7K    0.782   0  \n",
       "4  audio_features  spotify:track:5ta4df06VXtrLMW9avtjV6    0.559   0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is Nan value or not\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above means there is no Nan value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataset into train data and test data. The proportion of train and test data is 75:25. Also, I use the \"stratified sampling\" to split the data with keeping the proportion of \"df.bbd\"(0 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df.bbd, random_state=None, stratify=df.bbd) #random_state->assign random seed(if None, it's gonna be differemt values every time you run it.) stratify->designate what you gonna use for stratify samplijng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74994617868676"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion is approximately 7.5:2.5.\n",
    "len(X_train)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44296875\n",
      "4.4402810304449645\n"
     ]
    }
   ],
   "source": [
    "# The proportion of \"bbd\" is also same.\n",
    "print(y_train.value_counts()[0]/y_train.value_counts()[1]) # train data\n",
    "print(y_test.value_counts()[0]/y_test.value_counts()[1]) # test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of training data should be identical to that of test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are some features which has big numerical difference between each value, it is necessary to normalize the data in the range[0 , 1], because the difference between the value in that feature would have much influence on the euclidean distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with non-numeric parameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean to binary numbers. About multiple possible values, I need to assign vector numbers so that the distance of each should be equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There mainly three evaluatio methods. Holdout set(when data is large), n-fold cross validation(when data is not large enough), validation set.<br>\n",
    "\"K\" should be large value to ignore some noisy value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
